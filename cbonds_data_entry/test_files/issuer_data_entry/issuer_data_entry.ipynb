{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import mysql.connector\n",
    "import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('issuer_to_masterid.json', 'r') as f:\n",
    "    isinToMasterid = json.load(f)\n",
    "with open('col_to_indicator_map.json', 'r', encoding='utf-8') as f:\n",
    "    colToIndicator = json.load(f)\n",
    "map_df = pd.read_csv('new_issuer_to_masterid.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_date = '2022-01-11'\n",
    "path = r'D:\\\\sriram\\\\agrud\\\\cbonds_data_entry\\\\server_files\\\\zipfiles\\\\data_files\\\\'+today_date+'\\\\'\n",
    "try:\n",
    "    df = pd.read_excel(path+'issuers.xls',dtype={'CIK number':str})\n",
    "except:\n",
    "    df = pd.read_csv(path+'issuers.csv', sep=';', encoding='latin')\n",
    "df.columns = df.columns.str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['full issuer name (eng)'].isna(), 'full issuer name (eng)'] = df.loc[df['full issuer name (eng)'].isna(), 'issuer short name (eng)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "for dt in map_df.to_dict(orient='records'):\n",
    "    for i,row in df.iterrows():\n",
    "        if dt['Full issuer name (eng)'] == row['full issuer name (eng)']:\n",
    "            row['master id'] = dt['master id']\n",
    "            new_df = new_df.append(row)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['master id'] = df['full issuer name (eng)'].map(isinToMasterid)\n",
    "new_df = new_df[new_df['master id'].notna()]\n",
    "binaryColumns = ['company doesn`t exist (yes/no)','spv (yes/no)','international issuer (yes/no)']\n",
    "new_df[binaryColumns] = new_df[binaryColumns].replace([[0], [1]], [[\"No\"], [\"Yes\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_date = '2020-01-01'\n",
    "result = []\n",
    "for i, row in new_df.iterrows():\n",
    "    row2 = row.to_dict()\n",
    "    masterId = row2['master id']\n",
    "    for k, v in row2.items():\n",
    "        if k in colToIndicator and pd.isna(v) == False:\n",
    "            indicatorId = colToIndicator[k]\n",
    "            if type(v) == str:\n",
    "                json_data = json.dumps({'TEXT':v})\n",
    "                dataType = 3\n",
    "                value_data = 0 \n",
    "            result.append([masterId,indicatorId,value_data,json_data,dataType,ts_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.DataFrame(result)\n",
    "# cols=['masterid','indicatorid','value_data','json_data','datatype','ts_date']\n",
    "# df2.columns = cols\n",
    "# df2.to_csv('issuers_data.csv',index=False,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 rows are inserted into db\n",
      "MySQL connection is closed\n"
     ]
    }
   ],
   "source": [
    "# insert query\n",
    "try:\n",
    "        db_conn = mysql.connector.connect(host='54.237.79.6',user='rentech_user',database = 'rentech_db',password='N)baegbgqeiheqfi3e9314jnEkekjb',auth_plugin='mysql_native_password')\n",
    "        cursor = db_conn.cursor()\n",
    "        sql = \"\"\"INSERT INTO `raw_data` (`id`, `master_id`, `indicator_id`, `value_data`, `json_data`, `data_type`, `ts_date`, `ts_hour`, `job_id`, `timestamp`) VALUES \n",
    "        (NULL, %s, %s, %s, %s, %s, %s, '0:0:0', 9, NOW()) ON DUPLICATE KEY UPDATE  \n",
    "        master_id = VALUES(master_id), indicator_id = VALUES(indicator_id), value_data = VALUES(value_data), json_data = VALUES(json_data),data_type = VALUES(data_type), ts_date = VALUES(ts_date) ,ts_hour = VALUES(ts_hour),\n",
    "        job_id = VALUES(job_id), batch_id = VALUES(batch_id);\"\"\"\n",
    "        cursor.executemany(sql, result)\n",
    "        print (f\"{cursor.rowcount} rows are inserted into db\")\n",
    "        db_conn.commit()\n",
    "except Exception as e:\n",
    "        print (\"Mysql Error:\",e)\n",
    "finally:\n",
    "        if(db_conn.is_connected()):\n",
    "                cursor.close()\n",
    "                db_conn.close()\n",
    "                print(\"MySQL connection is closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c40bc86b65c221928a8dcb60bcd533d914928a478170fa7541d6a17a6588b245"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
